{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "K_Nearest_Neighbors_(KNN).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "dAO2bb0bDpI-",
        "_Ugs5pUdVtaS"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAO2bb0bDpI-"
      },
      "source": [
        "#### Copyright 2020 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO30fGEDDrkO"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "LjFnI22EFDIo"
      },
      "source": [
        "# K-Nearest-Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn1krl8WC4kC"
      },
      "source": [
        "The k-nearest neighbors (KNN) algorithm is a simple concept: define some distance metric between the items in your dataset, and find the K closest items. You can then use those items to predict some property of a test item. This prediction is achieved by having them somehow \"vote\" on it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DucpmlICqfV"
      },
      "source": [
        "## KNN for Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgl3IeAgEUEr"
      },
      "source": [
        "In this example we will use KNN to predict whether or not a person will be diagnosed with diabetes. The dataset is the [Pima Indians Diabetes Database](https://www.kaggle.com/uciml/pima-indians-diabetes-database).\n",
        "\n",
        "Upload your `kaggle.json` file and run the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYcD3rqsiQLw"
      },
      "source": [
        "! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && mv kaggle.json ~/.kaggle/ && echo 'Done'\n",
        "! kaggle datasets download uciml/pima-indians-diabetes-database\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKAHb-9eipy7"
      },
      "source": [
        "Unzip the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thXepCahitIp"
      },
      "source": [
        "! unzip pima-indians-diabetes-database.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r3apj-qirmF"
      },
      "source": [
        "And then load the dataset into a `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5-QyBteDws3"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "diabetes = pd.read_csv('diabetes.csv')\n",
        "diabetes.sample(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBXxoEeYi_YH"
      },
      "source": [
        "Take a quick look at the data to see how many rows and columns we are dealing with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_ysgP9sEHyv"
      },
      "source": [
        "diabetes.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CB2QMgVEsag"
      },
      "source": [
        "Our features are:\n",
        "- Pregnancies\n",
        "- Glucose\n",
        "- BloodPressure\n",
        "- SkinThickness\n",
        "- Insulin\n",
        "- BMI\n",
        "- DiabetesPedigreeFunction\n",
        "- Age\n",
        "\n",
        "Our target is `Outcome`, which is currently encoded with a 1 for a positive diagnosis and 0 for a negative diagnosis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8zDRrH2E1sk"
      },
      "source": [
        "print(diabetes.groupby('Outcome').size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YYpRLoVG9M0"
      },
      "source": [
        "Notice there are several zeros in the feature columns (check the **min** values). These are likely cases where the data simply wasn't collected or stored properly. (For example, a blood pressure of 0 does not make sense.) We need to clean these up or they will have an incorrect effect on the outcome of our KNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaKRyuhXHdDT"
      },
      "source": [
        "import numpy as np\n",
        "no_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "\n",
        "for column in no_zero:\n",
        "  diabetes[column] = diabetes[column].replace(0, np.NaN)\n",
        "  mean = int(diabetes[column].mean(skipna=True))\n",
        "  diabetes[column] = diabetes[column].replace(np.NaN, mean)\n",
        "\n",
        "diabetes.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP_5N-vVFwcZ"
      },
      "source": [
        "We create training and testing sets (20% for testing), remembering to separate 'Outcome' as our target value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sxRClkUI_80"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = diabetes.iloc[:,0:8]\n",
        "y = diabetes.iloc[:,8]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNmQ-WJSG8U1"
      },
      "source": [
        "Now we scale our features using StandardScaler. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUweJhpqJ7-J"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test= sc_X.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzS68VfgKzs4"
      },
      "source": [
        "Finally, we use the scikit-learn KNN model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STqlJ4B6Kuzk"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "n_neighbors = 14\n",
        "\n",
        "KNN = KNeighborsClassifier(n_neighbors=n_neighbors, p=2, metric='euclidean')\n",
        "KNN.fit(X_train, y_train)\n",
        "\n",
        "y_pred = KNN.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JFuPHd0MlSo"
      },
      "source": [
        "We now evaluate our model in terms of the confusion matrix, F1 score, and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6WbuXywMsT5"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "f1 = f1_score(y_test,y_pred)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "\n",
        "print('The confusion matrix is', cm)\n",
        "print('The F1 score is', f1)\n",
        "print('The accuracy score is', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a89atWiVOWGQ"
      },
      "source": [
        "## K-Nearest-Neighbors for Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDXgoCAXxExG"
      },
      "source": [
        "We can also use KNN for regression. In this example we'll actually build the model from scratch in order to demonstrate its simplicity.\n",
        "\n",
        "For our model we'll use MovieLens data. MovieLens data is available in relation to the following paper:\n",
        "\n",
        "```text\n",
        "F. Maxwell Harper and Joseph A. Konstan. 2015.\n",
        "The MovieLens Datasets: History and Context.\n",
        "ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19.\n",
        "https://doi.org/10.1145/2827872\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9UAjEelkkpX"
      },
      "source": [
        "! wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "! unzip ml-latest-small.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oVdwx-o4hts"
      },
      "source": [
        "We'll use KNN to guess the rating of a movie by looking at the 10 movies that are closest to it in terms of genres and popularity.\n",
        "\n",
        "To start, let's load up every rating in the dataset into a Pandas DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "fxzo6I1RFDIq"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
        "ratings.sample(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "vaMWVgAuFDIw"
      },
      "source": [
        "Now we'll group everything by `movieId` and compute the mean rating for the movie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQNlvKjHnFXE"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "mean_ratings = ratings[['movieId', 'rating']].groupby('movieId').agg({'rating': ['sum', 'mean']})\n",
        "mean_ratings.columns = ['rating_count', 'mean_rating']\n",
        "mean_ratings.sample(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "uDe77nJjFDI1"
      },
      "source": [
        "There is likely a fair amount of variance in the sum of ratings, so we'll normalize that column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "W1IsBi8gFDI2"
      },
      "source": [
        "mean_ratings['rating_count'] = (\n",
        "    (mean_ratings['rating_count'] - mean_ratings['rating_count'].min()) / \n",
        "    (mean_ratings['rating_count'].max() - mean_ratings['rating_count'].min()))\n",
        "\n",
        "mean_ratings['rating_count'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Mgy7PuTYFDI5"
      },
      "source": [
        "Now let's get the genre information from the `movies.csv` file. In the genres column, we see the list of genres for each movie separated by a `'|'`. Note that a movie may have more than one genre. \n",
        "\n",
        "First we read the file into a DataFrame. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0Il1YUZCu5N"
      },
      "source": [
        "movies = pd.read_csv('./ml-latest-small/movies.csv')\n",
        "movies.sample(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT6kSrhE0YGv"
      },
      "source": [
        "movies.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55Rl0TPgv6YD"
      },
      "source": [
        "Now we split the genres column on the `'|'` and create a new DataFrame called `movies_split`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J5xMDq7vr4W"
      },
      "source": [
        "movies_split = movies.genres.str.split('|', expand=True)\n",
        "movies_split.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xuTZEM4J9i5"
      },
      "source": [
        "We now create a list of all the unique genres that appear in this DataFrame and remove values that indicate that a genre wasn't specified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUPXs_XBwlw9"
      },
      "source": [
        "genres = list(pd.unique(movies_split.values.ravel()))\n",
        "genres.remove(None)\n",
        "genres.remove('(no genres listed)')\n",
        "genres = sorted(genres)\n",
        "genres"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQDnShPNw6YT"
      },
      "source": [
        "In the movies DataFrame, we want to recode the values of the genres column to be a list of 20 0s and 1s that correspond to the values in `list` (in the order that they appear in `list`). For example, if a movie has genres 'Adventure and Children', then we would like the element in the genres column to be: \\\n",
        "`[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySlaMGAtqq9e"
      },
      "source": [
        "genre_to_id = {v:i for i, v in enumerate(genres)}\n",
        "genre_to_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itN7X7X-yZ2G"
      },
      "source": [
        "The function defined below iterates through a list of genres and compares the values to the elements of `genres_list`. It then returns an appropriate array of 0s and 1s as described above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiC9efbJyYmk"
      },
      "source": [
        "# Create the array of 0s and 1s based on genres.\n",
        "def encode_genres(l):\n",
        "  encoding = np.zeros(len(genres)).astype(int)\n",
        "  for genre in l:\n",
        "    if genre in genre_to_id:\n",
        "      encoding[genre_to_id[genre]] = 1\n",
        "  return encoding\n",
        "\n",
        "# Test that f works as expected on an example list.\n",
        "encode_genres(['Adventure', 'Children'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfRuqHf6zjU5"
      },
      "source": [
        "We split the genres column of the movies DataFrame to be a list. We do this in preparation for applying the function, `encode_genres`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8nMO-TxtKqP"
      },
      "source": [
        "movies['genres'] = movies.genres.str.split('|')\n",
        "movies.sample(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyheaFd60-sr"
      },
      "source": [
        "We apply the function `encode_genres` to the genres column to change the elements to arrays of 0s and 1s representing the genres. We also set the index to be the `movieId`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngyoL_vDuKG2"
      },
      "source": [
        "movies['genres'] = movies.genres.apply(encode_genres)\n",
        "movies = movies.set_index('movieId')\n",
        "movies.sample(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on2vh-5lSWHJ"
      },
      "source": [
        "Now we can add the mean rating and the count of ratings to the movies. Let's first make sure that every index is accounted for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hiNP3aASe9e"
      },
      "source": [
        "np.setdiff1d(movies.index.to_numpy(), mean_ratings.index.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Baxr5N57Smzd"
      },
      "source": [
        "np.setdiff1d(mean_ratings.index.to_numpy(), movies.index.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRU0CMCjSqK3"
      },
      "source": [
        "It looks like we are missing some IDs from the ratings, so we need to be sure to do an inner join. We don't want to include movies with no ratings or ratings with no movies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsLyPq_BSpwt"
      },
      "source": [
        "movies = movies.join(mean_ratings, how='inner')\n",
        "movies.sample(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "KJNB_C6yFDJC"
      },
      "source": [
        "Now let's define a function that computes the \"distance\" between two movies based on how similar their genres are and how similar their popularity is. To make sure it works, we'll compute the distance between movie IDs `2` and `2728`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwzbEaa1ssJT"
      },
      "source": [
        "from scipy import spatial\n",
        "\n",
        "def distance(a, b):\n",
        "  genre_distance = spatial.distance.euclidean(a['genres'], b['genres'])\n",
        "  popularity_distance = abs(a['rating_count'] - b['rating_count'])\n",
        "  return genre_distance + popularity_distance\n",
        "    \n",
        "distance(movies[movies.index == 2].iloc[0], movies[movies.index == 2728].iloc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "PykcDKS9FDJG"
      },
      "source": [
        "Remember, the higher the distance, the less similar the movies are. Let's check what movies `2` and `2728` actually are, and then let's confirm they're not all that similar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "YdtviIH_FDJH"
      },
      "source": [
        "print(movies[movies.index == 2].iloc[0])\n",
        "print(movies[movies.index == 2728].iloc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "MZeyQceHFDJK"
      },
      "source": [
        "Now we just need a little code to compute the distance between some given test movie (Toy Story, in this example) and all of the movies in our dataset.\n",
        "\n",
        "We'll find the `10` nearest neighbors utilizing a `heapq` to keep our memory usage low. Note that `heapq` pops the smallest values first, so we need to take the negative of the distance in order to remove the largest neighbors first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Lh8rhcoEFDJK"
      },
      "source": [
        "import heapq\n",
        "\n",
        "def k_nearest_neighbors(movie_id, K):\n",
        "    distances = []\n",
        "    central_movie = movies[movies.index == movie_id].iloc[0]\n",
        "    for mid, movie in movies.iterrows():\n",
        "        if (mid != movie_id):\n",
        "            dist = distance(central_movie, movie)\n",
        "            if len(distances) < K:\n",
        "              heapq.heappush(distances, (-dist, mid))\n",
        "            else:\n",
        "              _ = heapq.heappushpop(distances, (-dist, mid))\n",
        "    return [x[1] for x in distances]\n",
        "\n",
        "avg_rating = 0.0\n",
        "for id in k_nearest_neighbors(1, 10):\n",
        "  neighbor = movies[movies.index == id].iloc[0]\n",
        "  print(neighbor['title'], neighbor['mean_rating'])\n",
        "  avg_rating += neighbor['mean_rating']\n",
        "\n",
        "print(\"\\nPredicted Rating: \", avg_rating/10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "IxqjFl8lFDJS"
      },
      "source": [
        "How does this compare to Toy Story's actual average rating?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "NqQXZlaVFDJS"
      },
      "source": [
        "movies[movies.index == 1].iloc[0]['mean_rating']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrp2xsTMEbsG"
      },
      "source": [
        "# Exercise: `KNeighborsRegressor`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSrVd6CaUxdJ"
      },
      "source": [
        "Earlier in the lab, we built a KNN regressor from scratch. Scikit-learn offers the [`KNeighborsRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html), which can perform the regression for us.\n",
        "\n",
        "In this exercise we'll again use the MovieLens dataset to predict rating. Instead of writing your own regressor, use the [`KNeighborsRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html). You'll need to load the data, prepare it for the regressor, and then build and train your model.\n",
        "\n",
        "Instead of building one model, build one hundred. Try using a neighbor count from `1` to `101`. Train your model using a new neighbor count each time. Keep some holdout data for testing, and calculate the root mean squared error for each neighbor count on the holdout data. Plot the RMSE data vs. the neighbor count to try to determine the optimal number of neighbors to consider for this dataset.\n",
        "\n",
        "Explain your work. Use as many code and text blocks as you need."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTKJ_SdZVpy_"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26J2x2-dVreE"
      },
      "source": [
        "# Your code goes here.\n",
        "hundred_movies = movies.sample(n=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "Ro2WwURY6w_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here.\n",
        "\n",
        "ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
        "ratings.sample(n=10)\n",
        "\n",
        "\n",
        "movies = pd.read_csv('./ml-latest-small/movies.csv')\n",
        "movies['ratings'] = ratings['rating']\n",
        "\n",
        "\n",
        "onehotEncodings = pd.get_dummies(movies['genres'])\n",
        "onehotEncodings\n",
        "for o in onehotEncodings.columns:\n",
        "  movies[o] = onehotEncodings.copy()[o]\n",
        "\n",
        "movies"
      ],
      "metadata": {
        "id": "qmC-m8m26m3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(movies[onehotEncodings.columns],movies['ratings'])\n",
        "y_train"
      ],
      "metadata": {
        "id": "59EO_-hJ6msQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here.\n",
        "\n",
        "rmses = []\n",
        "for i in range(1, 102):\n",
        "  regress = KNeighborsRegressor(n_neighbors=i)\n",
        "  regress.fit(X_train,y_train)\n",
        "  predict = regress.predict(X_test)\n",
        "  rmses.append(mean_squared_error(y_test,predict,squared=False))"
      ],
      "metadata": {
        "id": "tT0goyuu6mgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "neighbors = list(range(1,102))\n",
        "plt.plot(neighbors,rmses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FalX1q8D6mTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.array(rmses).argmin()+1)"
      ],
      "metadata": {
        "id": "_CT4nYUe7cSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMAutxgZVszk"
      },
      "source": [
        "---"
      ]
    }
  ]
}